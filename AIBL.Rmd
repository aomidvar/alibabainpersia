---
title: "AIBL"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

How the Machine Learning help doctors as part of Dementia Diagnosis with the highest degree of accuracy and reliability from medical record and neuropsychological assessment of AIBL.
What are the important predictors? 
Which part of the Computational Resources, methods of Data Mining activities are the most important and why. Algorithms, Accuracy, Pre-processing, ethical issue, etc.
Hint: AI Ethical issue has  a fair complicated cases.
Is there any validation model framework available to practically align  Data Mining with the needs of all their stakeholders.


```{r AIBL}



x_testdata <- read.csv("c:/users/lenovo/desktop/test.csv")

x_traindata <- read.csv("c:/users/lenovo/desktop/train.csv")




# Code for installation of the required Libraries

#install.packages("earth", lib="C:/Users/YourUser/Documents/R/win-library/3.3")

library(mlbench)
library(party)
library(tidyverse)
library(caret)
library(ranger)
library(e1071)
library(ggplot2)
library(dplyr)
library(Hmisc)
library(readxl)
library(plotrix)
library(ggcorrplot)
library(dplyr)
library(GGally)
library(PerformanceAnalytics)
library(cowplot)
library(caret)
library(rpart)
library(rpart.plot)
library(e1071)
library(randomForest)
library(gbm)
library(Metrics)
library(varImp)
library(vtreat)
library(AUC)
library(Boruta)


#code for Pre-processing, feature engineering and variable evaluation

set.seed(123)
describe(x_traindata)
chart.Correlation(select(x_traindata, CDGLOBAL,LDELTOTAL, MMSCORE, MH8MUSCL, HMT7,HMT13,RCT20, RCT392, APGEN2, MH6HEPAT, BAT126, MH9ENDO), histogram = TRUE, main = "Correlation between Variables")

str(x_traindata)
str(x_testdata)
x_traindata$class <-factor(x_traindata$class)


#boruta <- Boruta(x_traindata$class ~ ., data = x_traindata, doTrace = 2, maxRuns = 100)
#boruta_signif <- names(boruta$finalDecision[boruta$finalDecision %in% c("Confirmed", "Tentative")])
#print(boruta_signif)  # significant variables
#plot(boruta, cex.axis=1.1, las=2, xlab="", main="Variable Importance")  # plot variable importance

library(earth)
marsModel <- earth(class ~ ., data=x_traindata) # build model
ev <- evimp (marsModel) # estimate variable importance
print(ev)

df = subset(x_traindata, select = c(CDGLOBAL,LDELTOTAL, MMSCORE, MH8MUSCL, HMT7,HMT13,RCT20, RCT392, APGEN2, MH6HEPAT, BAT126, MH9ENDO, class) )
```

## Including modelling with new variables and testing and training the data

The model are then evaluated by the comparison with the test data, with the model selected, on the Result evaluation with the help of environmental variables in Support Vector Classifier, NaÃ¯ve Bayes, Random Forest

```{r pressure, echo=FALSE}
svm_model<-svm(class~.,data=df, gamma=0.1)

rf_model <- train(
  class~.,
  tuneLength = 1,
  data = df, 
  method = "rf",
  trControl = trainControl(
    method = "cv", 
    number = 10, 
    verboseIter = TRUE))
  
nb_model<-naiveBayes(df,df$class)
nb_predict<-predict(nb_model,df,type="class")
view(nb_predict)

proc.time()


class.svm.model <- svm(class ~ ., data = df,cost=10, cross=10,type="C-classification",kernel="radial",na.action=na.omit)
proc.time()
svm_predict<-predict(class.svm.model,df,type="class")
view(svm_predict)

class.svm.model$tot.accuracy
#table(class.svm.model$class, svm_predict$class)


rf_model
nb_model



AIBL.nb_model.prediction <-predict(nb_model, newdata = as.list(df, function(x) subset(df, is.na(df$class))                                                                                        ))

table(df$class, AIBL.nb_model.prediction)

AIBL.rf_model.prediction <-predict(rf_model, newdata = as.list(df, function(x) subset(df, is.na(df$class))                                                                                        ))



class.svm.model
svm_model


```

